import streamlit as st
import torch
from torchvision import models, transforms
from PIL import Image
import os
import base64
from fpdf import FPDF
from datetime import datetime  # æ—¥æ™‚ã®å–å¾—ã«ä½¿ç”¨
from io import BytesIO  # ä¸€æ™‚ãƒ‡ãƒ¼ã‚¿ä¿å­˜ã«ä½¿ç”¨

# ===== Streamlit ãƒšãƒ¼ã‚¸è¨­å®š =====
st.set_page_config(page_title="Tryna use Mxxxxy", layout="wide")

# ===== èƒŒæ™¯ç”»åƒã‚’Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ =====
def get_base64_of_bin_file(bin_file):
    with open(bin_file, 'rb') as f:
        data = f.read()
    return base64.b64encode(data).decode()

background_image_path = "C:/Users/E.ykt/Desktop/1009_è‡ªèµ°èª²é¡Œ/background.png"

if os.path.exists(background_image_path):
    print(f"èƒŒæ™¯ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ: {background_image_path}")
    img_base64 = get_base64_of_bin_file(background_image_path)
else:
    print(f"èƒŒæ™¯ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ: {background_image_path}")
    img_base64 = ""

# ===== ã‚«ã‚¹ã‚¿ãƒ CSSã§èƒŒæ™¯ç”»åƒã‚’è¨­å®š =====
st.markdown(
    f"""
    <style>
    .stApp {{
        background-image: url("data:image/png;base64,{img_base64}");
        background-size: cover;
        background-position: center;
        background-attachment: fixed;
    }}
    .sidebar .sidebar-content {{
        background-color: rgba(0, 0, 0, 0.7);
        color: white;
    }}
    h1 {{
        color: #FF4B4B;
        text-align: center;
    }}
    .stButton>button {{
        background-color: #FF4B4B;
        color: white;
        border-radius: 10px;
    }}
    </style>
    """,
    unsafe_allow_html=True
)

# ===== ã‚¿ã‚¤ãƒˆãƒ«ã®è¡¨ç¤º =====
st.markdown(
    """
    <h1>
    â€œã‚ã®â€ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã€ä½¿ãˆã‚‹ï¼Ÿ<br>ç”»åƒåˆ¤å®š
    </h1>
    """,
    unsafe_allow_html=True
)

# ===== ãƒ¢ãƒ‡ãƒ«ã®å®šç¾© =====
class ImageAuthClassifier(torch.nn.Module):
    def __init__(self):
        super(ImageAuthClassifier, self).__init__()
        self.resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)
        num_ftrs = self.resnet.fc.in_features
        self.resnet.fc = torch.nn.Linear(num_ftrs, 2)

    def forward(self, x):
        return self.resnet(x)

# ===== ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰é–¢æ•° =====
def load_model(model_path="model.pth"):
    model = ImageAuthClassifier()
    state_dict = torch.load(model_path, map_location=torch.device('cpu'), weights_only=True)
    model.load_state_dict(state_dict)
    model.eval()
    return model

# ===== ç”»åƒã®å‰å‡¦ç† =====
transform = transforms.Compose([
    transforms.Resize((630, 630)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# ===== PDFç”Ÿæˆé–¢æ•° =====
def generate_pdf(image_data, image_name, result, timestamp):
    pdf = FPDF()
    pdf.add_page()

    font_path = "C:/Windows/Fonts/msgothic.ttc"
    pdf.add_font("Gothic", "", font_path, uni=True)
    pdf.set_font("Gothic", size=20)

    pdf.cell(200, 10, txt="ç”»åƒåˆ¤å®šãƒ¬ãƒãƒ¼ãƒˆ", new_x="LMARGIN", new_y="NEXT", align='C')
    pdf.set_font("Gothic", size=16)
    pdf.ln(10)
    pdf.cell(200, 10, txt=f"ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å: {image_name}", new_x="LMARGIN", new_y="NEXT", align='L')
    pdf.ln(5)
    pdf.cell(200, 10, txt=f"åˆ¤å®šæ—¥æ™‚: {timestamp}", new_x="LMARGIN", new_y="NEXT", align='L')
    pdf.ln(10)
    pdf.cell(200, 10, txt=f"åˆ¤å®šçµæœ: {result}", new_x="LMARGIN", new_y="NEXT", align='L')
    pdf.ln(10)

    # ä¸€æ™‚çš„ãªç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’PDFã«è¿½åŠ 
    temp_image_path = BytesIO(image_data)
    pdf.image(temp_image_path, x=60, y=None, w=100)

    # PDFã‚’ä¸€æ™‚ãƒãƒƒãƒ•ã‚¡ã«ä¿å­˜
    pdf_buffer = BytesIO()
    pdf.output(pdf_buffer)
    pdf_buffer.seek(0)  # ãƒãƒƒãƒ•ã‚¡ã®å…ˆé ­ã«ç§»å‹•
    return pdf_buffer

# ===== Streamlitã‚¢ãƒ—ãƒª =====
with st.sidebar:
    st.header("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    uploaded_file = st.file_uploader("ç”»åƒã‚’é¸æŠã—ã¦ãã ã•ã„", type=["jpg", "png", "jpeg"])

model = load_model("model.pth")

if uploaded_file is not None:
    image = Image.open(uploaded_file).convert("RGB")
    st.image(image, caption="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒ", width=300)

    width, height = image.size
    st.write(f"ç”»åƒã‚µã‚¤ã‚º: **{width} x {height}** ãƒ”ã‚¯ã‚»ãƒ«")

    if st.button("ç”»åƒã‚’åˆ¤å®š"):
        with st.spinner('åˆ¤å®šä¸­...å°‘ã€…ãŠå¾…ã¡ãã ã•ã„'):
            input_tensor = transform(image).unsqueeze(0)
            with torch.no_grad():
                output = model(input_tensor)
                _, predicted = torch.max(output, 1)

            class_names = ["ä½¿ç”¨å¯èƒ½", "ä½¿ç”¨ä¸å¯"]
            result = class_names[predicted.item()]

        if result == "ä½¿ç”¨å¯èƒ½":
            st.success(f"äºˆæ¸¬çµæœ: **{result}** ğŸŸ¢")
        else:
            st.error(f"äºˆæ¸¬çµæœ: **{result}** ğŸ”´")

        image_name = uploaded_file.name.split('.')[0]
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        # ç”»åƒã‚’ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›
        image_buffer = BytesIO()
        image.save(image_buffer, format='PNG')
        image_data = image_buffer.getvalue()

        # PDFã®ç”Ÿæˆã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        pdf_buffer = generate_pdf(image_data, image_name, result, timestamp)

        st.download_button(
            label="ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=pdf_buffer,
            file_name=f"{image_name}_åˆ¤å®šãƒ¬ãƒãƒ¼ãƒˆ.pdf",
            mime="application/pdf"
        )
